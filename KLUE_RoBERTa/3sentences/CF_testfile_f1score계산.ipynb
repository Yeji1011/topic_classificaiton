from IPython.core.interactiveshell import InteractiveShell
InteractiveShell.ast_node_interactivity = "all"

import torch

device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
print(device)
print('Available device : ', torch.cuda.device_count())
print('Current cuda device :', torch.cuda.current_device())
print(torch.cuda.get_device_name(device))

# Setting parameters
batch_size = 300
num_label = 7
learning_rate = 1e-5
max_grad_norm = 1
# epochs = 1
num_workers = 8
# max_len = 512

import time
start_time = time.time()

from transformers import BertTokenizer, RobertaTokenizer, RobertaForSequenceClassification
import torch

config = 'klue/roberta-large'
tokenizer = BertTokenizer.from_pretrained(config)
model = RobertaForSequenceClassification.from_pretrained(config, num_labels=num_label)

model.to(device)

model_save_dir='/home/yeji/standard/model/topic3/3sentences/saved_model/20211127_195801/epoch_6.pt'

learning_rate = 1e-5
optimizer = torch.optim.AdamW(model.parameters(), lr=learning_rate)
checkpoint = torch.load(model_save_dir)

# 원래 module. 없어야됨
# 근데 생겨서 지움
new_checkpoint = { k.replace('module.','') if 'module.' in k else k:v for k,v in checkpoint['model_state_dict'].items()}

model.load_state_dict(new_checkpoint)#checkpoint['model_state_dict'])
optimizer.load_state_dict(checkpoint['optimizer_state_dict'])
epoch = checkpoint['epoch']
# model.to(device)

model.eval()
print('Model loaded!')


import pandas as pd

test_path ='/home/yeji/standard/model/topic3/3sentences/experiment_dataset/topic_test_dataset.csv'
test_df = pd.read_csv(test_path)  
# test_df=test_df[:10]

from torch.utils.data import Dataset, DataLoader

class Dataset(Dataset):
    def __init__(self, df):
        self.df = df

    def __len__(self):
        return len(self.df)

    def __getitem__(self, idx):
        text = self.df.iloc[idx, 0]
        #         print(text)

        label = self.df.iloc[idx, 1]
        #         print(label)
        return text, label


test_dataset = Dataset(test_df)  
test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False, num_workers=num_workers)




import torch.nn.functional as F
from tqdm import tqdm

def test():
    model.eval()
    
    total_loss = 0
    total_len = 0
    total_correct = 0
    
    global predicted_labels
    global true_labels

    predicted_labels=[]
    true_labels=[]    
    for text, label in tqdm(test_loader):
        # print("Running Validation...")
        true_labels.append(label)
#         print('label', label)
        
        encoded_list = [tokenizer.encode(t, add_special_tokens=True) for t in text]
        padded_list = [e + [0] * (510 - len(e)) for e in encoded_list]

        sample = torch.tensor(padded_list)
        sample, label = sample.to(device), label.to(device)
        labels = label.clone().detach()
       
        with torch.no_grad():
            outputs = model(sample, labels=labels)
        _, logits = outputs

        pred = torch.argmax(F.softmax(logits, dim=1), dim=1)
        correct = pred.eq(labels)
        total_correct += correct.sum().item()
        total_len += len(labels)
        
        pred = pred.detach().cpu().numpy()
        predicted_labels.append(pred)
#         print('pred', pred)

        
    return true_labels, predicted_labels
#     return label, pred, predicted_labels, true_labels

    print('Test accuracy: {:.4f}'.format(total_correct / total_len))
    
    now = time.gmtime(time.time() - start_time)
    print('{} hours {} mins {} secs for training'.format(now.tm_hour, now.tm_min, now.tm_sec))

test()

len(true_labels), len(predicted_labels)

cf_true_labels=[]
cf_predicted_labels=[]

for labels, preds in zip(true_labels, predicted_labels):    
    for label, pred in zip(labels, preds):
        label=label.tolist()
        cf_true_labels.append(label)
        cf_predicted_labels.append(pred)




import numpy as np

num_label = 7
num_pred = 7

confusion_matrix = np.zeros((num_label, num_pred), dtype = "int32") #제로 에러이 생성
# print('target_pred_counting', target_pred_counting)
idx_to_chr =  {0: "경제", 1: "취미", 2: "쇼핑", 3: "스포츠", 4: "정치", 5: "여행", 6: "기타"}
chr_to_idx ={"경제":0, "취미":1, "쇼핑":2, "스포츠":3,"정치":4, "여행":5, "기타":6}

for cf_label, cf_pred in zip(cf_true_labels, cf_predicted_labels):
    confusion_matrix[cf_label][cf_pred] +=1    
print(confusion_matrix)
# sum(confusion_matrix)    
# np.sum(confusion_matrix)

[[196   7   0   1  10   0  20]
 [  1 764   1   8  10   3  37]
 [  0   1 789   0   1   2   4]
 [  3  25   1 344   6   0  18]
 [  5  16   2   0 419   1  23]
 [  0  12  16   1   0 761   8]
 [ 10  23   2   6  27   5 659]]

cf_matrix=confusion_matrix


import numpy as np
from numpy import linalg as LA

#노멀라이제이션
# 1. 혼동행렬(Array상태)의 가로방향별로 각 input별 합을 구한다
total=np.sum(cf_matrix, axis=1)
print('total', total) 
# total [234 824 797 397 466 798 732]

#total[:, None]
array([[234],
       [824],
       [797],
       [397],
       [466],
       [798],
       [732]])


print(cf_matrix,'\n')
print(total,'\n')
[[196   7   0   1  10   0  20]
 [  1 764   1   8  10   3  37]
 [  0   1 789   0   1   2   4]
 [  3  25   1 344   6   0  18]
 [  5  16   2   0 419   1  23]
 [  0  12  16   1   0 761   8]
 [ 10  23   2   6  27   5 659]] 

[234 824 797 397 466 798 732] 

#re_matrix=cf_matrix/total
re_matrix = np.zeros((7,7))
re_matrix[0] = cf_matrix[0]/total[0]
re_matrix[1] = cf_matrix[1]/total[1]
re_matrix[2] = cf_matrix[2]/total[2]
re_matrix[3] = cf_matrix[3]/total[3]
re_matrix[4] = cf_matrix[4]/total[4]
re_matrix[5] = cf_matrix[5]/total[5]
re_matrix[6] = cf_matrix[6]/total[6]
print('re_matrix', re_matrix)




import seaborn as sns
import pandas as pd
df_cm = pd.DataFrame(re_matrix, index=['Economy', 'Hobby', 'Shopping', 'Sports', 'Politics', 'Travel', 'Etc'], columns=['Economy', 'Hobby', 'Shopping', 'Sports', 'Politics', 'Travel', 'Etc'])
df_cm




import matplotlib.pyplot as plt

plt.figure(figsize=(9,7))
plt.title("Confusion Matrix for 3 utterance of Topic Classification")
ax=sns.heatmap(df_cm,  fmt='.0%', cmap='Blues', annot=True,  annot_kws={"size": 12})

# ax.figure.axes[-1].yaxis.label.set_size(70)
plt.ylabel('True Class')
plt.xlabel('Predicted Class')
plt.xticks(fontsize =15)
plt.yticks(fontsize =15)
plt.setp(ax.get_xticklabels(), fontsize =12) #x축레이블
plt.setp(ax.get_yticklabels(), fontsize =12) #x축레이블


from sklearn.metrics import classification_report

# y_true = [0, 0, 0, 1, 1, 0, 0]
# y_pred = [0, 0, 0, 0, 1, 1, 1]

target_names=['Economy', 'Hobby', 'Shopping', 'Sports', 'Politics', 'Travel', 'Etc']
print(classification_report(cf_true_labels, cf_predicted_labels, target_names=target_names))












